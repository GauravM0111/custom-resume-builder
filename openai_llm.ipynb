{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592677ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI() # defautls to getting the key using os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload LinkedIn profile to OpenAI\n",
    "profile = client.files.create(\n",
    "  file=open(\"LinkedIn_profile.json\", \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in contents of job description\n",
    "with open(\"job_description.json\", \"r\") as f:\n",
    "    job_description = f.read()\n",
    "print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the example linkedIn profile to this thread\n",
    "# OpenAI automatically creates a vector store for the file that expires in 7 days\n",
    "thread = client.beta.threads.create(\n",
    "    tool_resources={\n",
    "        'file_search': {\n",
    "            'vector_stores': [\n",
    "                {\n",
    "                    'file_ids': [profile.id]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': job_description\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd325008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=os.environ.get(\"ASSISTANT_ID\")\n",
    ")\n",
    "\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca0e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive all run steps\n",
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    ")\n",
    "\n",
    "# Find message creation text step and extract content\n",
    "text_creation_step = run_steps.data[0]\n",
    "message_id = text_creation_step.step_details.message_creation.message_id\n",
    "\n",
    "message = client.beta.threads.messages.retrieve(\n",
    "  message_id=message_id,\n",
    "  thread_id=thread.id,\n",
    ")\n",
    "\n",
    "message_text = message.content[0].text.value\n",
    "print(message_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b890a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Extract the JSON resume from the message content\n",
    "start = message_text.index(\"```json\") + 7\n",
    "end = message_text.index(\"```\", start)\n",
    "\n",
    "json_resume = json.loads(message_text[start:end])\n",
    "print(json_resume)\n",
    "\n",
    "with open('custom_resume.json', 'w') as output_file:\n",
    "    json.dump(json_resume, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
